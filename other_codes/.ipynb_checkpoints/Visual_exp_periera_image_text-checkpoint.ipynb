{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_accuracy(actual, predicted):\n",
    "    true = 0\n",
    "    total = 0\n",
    "    for i in range(0,len(actual)):\n",
    "        for j in range(i+1, len(actual)):\n",
    "            total += 1\n",
    "\n",
    "            s1 = actual[i]\n",
    "            s2 = actual[j]\n",
    "            b1 = predicted[i]\n",
    "            b2 = predicted[j]\n",
    "\n",
    "            result1 = spatial.distance.cosine(s1, b1)\n",
    "            result2 = spatial.distance.cosine(s2, b2)\n",
    "            result3 = spatial.distance.cosine(s1, b2)\n",
    "            result4 = spatial.distance.cosine(s2, b1)\n",
    "\n",
    "            if(result1 + result2 < result3 + result4):\n",
    "                true += 1\n",
    "\n",
    "    return(true/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebc3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearcorr(actual, predicted):\n",
    "    corr = []\n",
    "    for i in range(0, len(actual)):\n",
    "        corr.append(np.corrcoef(actual[i],predicted[i])[0][1])\n",
    "    return np.mean(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdm_gen(data):\n",
    "    # calculate the values in RDM\n",
    "    abs=True\n",
    "    rdm = np.zeros([len(data),len(data)])\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            # calculate the Pearson Coefficient\n",
    "            r = pearsonr(data[i], data[j])[0]\n",
    "            # calculate the dissimilarity\n",
    "            if abs == True:\n",
    "                rdm[i, j] = 1 - np.abs(r)\n",
    "            else:\n",
    "                rdm[i, j] = 1 - r\n",
    "\n",
    "    return rdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63baf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdm_sim(rdm1, rdm2):\n",
    "    rp = np.array(pearsonr(rdm1.flatten(), rdm2.flatten()))\n",
    "    return rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d769833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indices(data):\n",
    "    Taskindices = []\n",
    "    for j in data['meta'][0][0][11][0][5]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Taskindices.append(int(k))\n",
    "    #print(len(Taskindices))\n",
    "    DMNindices = []\n",
    "    for j in data['meta'][0][0][11][0][6]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            DMNindices.append(int(k))\n",
    "    #print(len(DMNindices))\n",
    "    Visualindices = []\n",
    "    Visualindices_body = []\n",
    "    Visualindices_face = []\n",
    "    Visualindices_object = []\n",
    "    Visualindices_scene = []\n",
    "    for j in data['meta'][0][0][11][0][9]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Visualindices_body.append(int(k))\n",
    "    for j in data['meta'][0][0][11][0][10]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Visualindices_face.append(int(k))\n",
    "    for j in data['meta'][0][0][11][0][11]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Visualindices_object.append(int(k))\n",
    "    for j in data['meta'][0][0][11][0][12]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Visualindices_scene.append(int(k))\n",
    "    \n",
    "    for j in data['meta'][0][0][11][0][13]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Visualindices.append(int(k))\n",
    "#     print(len(Visualindices))\n",
    "    Languageindices_lh = []\n",
    "    Languageindices_rh = []\n",
    "    for j in data['meta'][0][0][11][0][7]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Languageindices_lh.append(int(k))\n",
    "    for j in data['meta'][0][0][11][0][8]:\n",
    "        for k in j[0]:\n",
    "            #print(k)\n",
    "            Languageindices_rh.append(int(k))\n",
    "        #Languageindices.append(int(j))\n",
    "    #print(len(Languageindices))\n",
    "    return Taskindices, DMNindices, Visualindices_body, Visualindices_face, Visualindices_object,Visualindices_scene, Visualindices, Languageindices_lh, Languageindices_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Y, X):\n",
    "    kf = KFold(n_splits=18)\n",
    "    \n",
    "    dataset_X = np.array(X.copy())\n",
    "    dataset_Y = np.array(Y.copy())\n",
    "    \n",
    "    actual = []\n",
    "    predicted = []\n",
    "    acc = []\n",
    "    corr = []\n",
    "    rdm_voxels = []\n",
    "\n",
    "    cnt = 0\n",
    "    for train_index, test_index in kf.split(dataset_X):\n",
    "\n",
    "        X_train, X_test = dataset_X[train_index], dataset_X[test_index]\n",
    "        y_train, y_test = dataset_Y[train_index], dataset_Y[test_index]\n",
    "           \n",
    "        model = Ridge(alpha=1.0)\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        cnt += 1\n",
    "#         print(cnt)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        actual.extend(y_test)\n",
    "        predicted.extend(y_pred)\n",
    "        \n",
    "        \n",
    "        acc1 = pairwise_accuracy(y_test, y_pred)\n",
    "        acc.append(acc1)\n",
    "        \n",
    "        corr1 = pearcorr(y_test, y_pred)\n",
    "        corr.append(corr1)\n",
    "        \n",
    "        rdm_act = rdm_gen(y_test)\n",
    "        rdm_pred = rdm_gen(y_pred)\n",
    "        rdm = rdm_sim(rdm_act, rdm_pred)\n",
    "        rdm_voxels.append(rdm[0])\n",
    "\n",
    "    return actual,predicted, round(np.mean(np.array(acc)),3), round(np.mean(np.array(corr)),3), round(np.mean(np.array(rdm_voxels)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIS = ['language_lh', 'language_rh', 'vision_body', 'vision_face', 'vision_object', 'vision_scene','vision', 'dmn', 'task']\n",
    "layers_resnet = ['block1','block2','block3','block4','fc']\n",
    "layers_vgg = ['maxpool1', 'maxpool2', 'maxpool3', 'maxpool4', 'maxpool5', 'fc6', 'fc7', 'fc8']\n",
    "layers_alexnet = ['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'fc6', 'fc7', 'fc8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_data(subject,layers):\n",
    "    file = open('../data/periera/stimuli_180concepts.txt','r')\n",
    "    lines = file.readlines()\n",
    "    images = [line.strip() for line in lines]\n",
    "    \n",
    "    data_pic = loadmat('../data/periera/'+subject+'/data_180concepts_pictures.mat')\n",
    "    Taskindices, DMNindices, Visualindices_body, Visualindices_face, Visualindices_object,Visualindices_scene, Visualindices, Languageindices_lh, Languageindices_rh = generate_indices(data_pic)\n",
    "    \n",
    "    roi_indices = {'language_lh':Languageindices_lh, 'language_rh':Languageindices_rh, \n",
    "        'vision_body': Visualindices_body, 'vision_face':Visualindices_face, \n",
    "        'vision_object': Visualindices_object, 'vision_scene': Visualindices_scene,\n",
    "        'vision': Visualindices,  'dmn': DMNindices, 'task': Taskindices}\n",
    "    \n",
    "    fmri = {}\n",
    "    for roi,indices in roi_indices.items():\n",
    "        fmri[roi] = data_pic['examples'][0:,np.array(indices)-1]\n",
    "    \n",
    "    \n",
    "    data = np.load('../data/features/periera/resnet_feat.npy',allow_pickle=True)\n",
    "    d = dict(enumerate(data.flatten(), 1))[1]\n",
    "    \n",
    "    dat = loadmat('../data/features/periera/180_captions_vec.mat')['roberta_avg']\n",
    "    \n",
    "    vis_feats = {}\n",
    "    for layer in layers:\n",
    "        cnt = 0\n",
    "        vis_feats[layer] = []\n",
    "        for img in images:\n",
    "            dt_visual = np.mean([d[img+'_1'][layer], d[img+'_2'][layer], d[img+'_3'][layer], d[img+'_4'][layer], d[img+'_5'][layer], d[img+'_6'][layer]], axis=0)\n",
    "            dt_textual = dat[cnt]\n",
    "            dt = np.concatenate([dt_visual,dt_textual])\n",
    "            vis_feats[layer].append(dt)\n",
    "\n",
    "    return fmri, vis_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['P01','M01','M02','M03','M04','M05','M06','M07','M08','M09','M10','M13','M14','M15','M16','M17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e437c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for roi in ROIS:\n",
    "    print(roi)\n",
    "    output = {}\n",
    "    output['2v2'] = {}\n",
    "    output['pear'] = {}\n",
    "    output['rdm_feats'] = {}\n",
    "    output['rdm_voxels'] = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        print(subject)\n",
    "        output['2v2'][subject] = []\n",
    "        output['pear'][subject] = []\n",
    "        output['rdm_feats'][subject] = []\n",
    "        output['rdm_voxels'][subject] = []\n",
    "        \n",
    "        fmri, vis_feats =  get_subject_data(subject, layers_resnet)\n",
    "        for layer in layers_resnet:\n",
    "            print(layer)\n",
    "            voxels = np.array(fmri[roi])\n",
    "            feats = np.array(vis_feats[layer])\n",
    "            actual,predicted, acc, corr, rdm_voxels = train(voxels,feats)\n",
    "            \n",
    "#             acc = pairwise_accuracy(actual, predicted)\n",
    "#             print(acc)\n",
    "            output['2v2'][subject].append(acc)\n",
    "#             corr = pearcorr(actual, predicted)\n",
    "#             print(corr)\n",
    "            output['pear'][subject].append(corr)\n",
    "            \n",
    "            rdm_feats = rdm_gen(feats)\n",
    "            rdm_actual = rdm_gen(actual)\n",
    "#             rdm_predicted = rdm_gen(predicted)\n",
    "            \n",
    "            rdm1 = rdm_sim(rdm_feats, rdm_actual)\n",
    "#             rdm2 = rdm_sim(rdm_actual, rdm_predicted)\n",
    "            \n",
    "            output['rdm_feats'][subject].append(round(rdm1[0],3))\n",
    "            output['rdm_voxels'][subject].append(rdm_voxels)\n",
    "            \n",
    "#             print(round(rdm1[0],3),rdm_voxels)\n",
    "            \n",
    "    fn = './results/'+roi+'_resnet.npy'\n",
    "    np.save(fn,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5a373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
